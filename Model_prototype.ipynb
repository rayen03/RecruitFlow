{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu4dtqd1ZnPXc93/KogXrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayen03/RecruitFlow/blob/model-improvements/Model_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joz7CDDHnbX2",
        "outputId": "64587727-3331-4d92-add9-07e92d04f7bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "D8_lWn4RKXGV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "dataDir='/content/drive/MyDrive/RecruitFlow'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EbIbHLCKaq0",
        "outputId": "5299514d-1b24-4e78-935c-9e1be7e786ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cv_data = pd.read_csv('/content/drive/MyDrive/RecruitFlow/parsedCV.csv')\n",
        "cv_data = cv_data.dropna()\n",
        "\n",
        "job_data = pd.read_csv('/content/drive/MyDrive/RecruitFlow/job_descriptions.csv')\n",
        "job_data = job_data.dropna()\n",
        "\n",
        "# Split\n",
        "cv_train, cv_test = train_test_split(cv_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data and create TaggedDocuments for Doc2Vec\n",
        "train_corpus = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(cv_train['Parsed_text'])]\n",
        "test_corpus = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(cv_test['Parsed_text'])]\n",
        "\n",
        "# Train  Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(vector_size=300, window=5, min_count=1, workers=4, epochs=20)\n",
        "doc2vec_model.build_vocab(train_corpus)\n",
        "doc2vec_model.train(train_corpus, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
        "\n",
        "# Embed job descriptions and CVs into vectors\n",
        "job_vectors = [doc2vec_model.infer_vector(text.split()) for text in job_data['job_description']]\n",
        "cv_vectors = [doc2vec_model.infer_vector(text.split()) for text in cv_test['Parsed_text']]\n",
        "\n",
        "# Calculate cosine similarity between job descriptions and CVs\n",
        "similarity_matrix = cosine_similarity(job_vectors, cv_vectors)\n",
        "\n",
        "# Normalize the similarity scores to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "normalized_similarity = scaler.fit_transform(similarity_matrix.T).T\n",
        "\n",
        "# Reset the index of cv_test DataFrame\n",
        "cv_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "BbLS-nxIi3MI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaHmHgSwKVa8",
        "outputId": "a2f285c2-1511-47d7-aadd-402af5d4d227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of job_vectors: (109, 300)\n",
            "Shape of cv_vectors: (497, 300)\n",
            "Shape of similarity_matrix: (109, 497)\n",
            "Shape of normalized_similarity: (109, 497)\n",
            "Length of cv_test: 497\n",
            "Length of ranking_scores: 497\n"
          ]
        }
      ],
      "source": [
        "#debug\n",
        "import numpy as np\n",
        "\n",
        "ranking_scores = normalized_similarity.argmax(axis=0) + 1\n",
        "print(\"Shape of job_vectors:\", np.shape(job_vectors))\n",
        "print(\"Shape of cv_vectors:\", np.shape(cv_vectors))\n",
        "print(\"Shape of similarity_matrix:\", np.shape(similarity_matrix))\n",
        "print(\"Shape of normalized_similarity:\", np.shape(normalized_similarity))\n",
        "print(\"Length of cv_test:\", len(cv_test))\n",
        "print(\"Length of ranking_scores:\", len(ranking_scores))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the 'Ranking_Score' column to cv_test\n",
        "cv_test['Ranking_Score'] = ranking_scores[:len(cv_test)]\n",
        "\n",
        "\n",
        "ranked_cvs_df = cv_test[['CV_ID', 'Parsed_text', 'Ranking_Score']].copy()\n",
        "\n",
        "# Display the first 10 ranked CVs\n",
        "top_10_cvs = ranked_cvs_df.sort_values(by='Ranking_Score', ascending=False).head(10).copy()\n",
        "top_10_cvs['CV_ID'] = top_10_cvs['CV_ID'].apply(lambda x: x.replace('/content/drive/MyDrive/RecruitFlow/ResumeDataset/', ''))\n",
        "\n",
        "top_10_cvs.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(top_10_cvs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icU2dptGi-Fe",
        "outputId": "0c7a769d-05bd-45b5-d2d5-61fa268f3f87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        CV_ID  \\\n",
            "0   CONSTRUCTION/25098739.pdf   \n",
            "1   CONSTRUCTION/15721849.pdf   \n",
            "2   CONSTRUCTION/30311725.pdf   \n",
            "3  DIGITAL-MEDIA/14771530.pdf   \n",
            "4  DIGITAL-MEDIA/10005171.pdf   \n",
            "5        FINANCE/28398216.pdf   \n",
            "6     HEALTHCARE/23918545.pdf   \n",
            "7             HR/20417897.pdf   \n",
            "8     ACCOUNTANT/78403342.pdf   \n",
            "9  DIGITAL-MEDIA/31909493.pdf   \n",
            "\n",
            "                                         Parsed_text  Ranking_Score  \n",
            "0  CONSTRUCTION WORKER\\nSummary\\nA motivated hard...            109  \n",
            "1  CONSTRUCTION PROJECT REGIONAL MANAGER\\nSummary...            109  \n",
            "2  SENIOR PROJECT MANAGER\\nProfessional Summary\\n...            109  \n",
            "3  DIGITAL PRODUCER\\nSummary\\nPersonable Project ...            106  \n",
            "4  MEDIA ACTIVITIES SPECIALIST\\nSummary\\n\\nMulti-...            106  \n",
            "5  FINANCE OFFICER\\nProfessional Summary\\nTo atta...            104  \n",
            "6  CLAIMS SERVICE SPECIALIST\\nProfessional Summar...            104  \n",
            "7  EXECUTIVE ASSISTANT HR\\nSummary\\nSkillful and ...            104  \n",
            "8  Self-motivated accountant offering a strong wo...            104  \n",
            "9  DIGITAL CLIENT LEAD\\nExperience\\n05/2014 to Cu...            102  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the  model\n",
        "\n",
        "doc2vec_model.save(\"/content/drive/MyDrive/RecruitFlow/modelData/doc2vec_model.model\")\n",
        "\n",
        "#save vectors\n",
        "vectors = [doc2vec_model.dv[i] for i in range(len(doc2vec_model.dv))]\n",
        "np.save(\"/content/drive/MyDrive/RecruitFlow/doc2vec_vectors.npy\", vectors)\n"
      ],
      "metadata": {
        "id": "RdZPfGyWo2T4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KvkytlxuB5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}