{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQQSGQKKFlBXL5h8D7EYGw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayen03/RecruitFlow/blob/model-improvements/Model_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "D8_lWn4RKXGV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "dataDir='/content/drive/MyDrive/RecruitFlow'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EbIbHLCKaq0",
        "outputId": "80d064e5-f5cb-4116-b175-21896d317519"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaHmHgSwKVa8",
        "outputId": "bbfb3e7d-72e3-4d13-b3cc-dcb06d45d838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 CV_ID  \\\n",
            "0                    ARTS/28471099.pdf   \n",
            "1    BUSINESS-DEVELOPMENT/22765255.pdf   \n",
            "2            CONSTRUCTION/28803888.pdf   \n",
            "3                    ARTS/18885767.pdf   \n",
            "4  INFORMATION-TECHNOLOGY/28897981.pdf   \n",
            "5                 FINANCE/18636651.pdf   \n",
            "6              CONSULTANT/12374933.pdf   \n",
            "7              ACCOUNTANT/28614791.pdf   \n",
            "8           DIGITAL-MEDIA/20628003.pdf   \n",
            "9                     BPO/31064969.pdf   \n",
            "\n",
            "                                         Parsed_text  Ranking_Score  \n",
            "0  OWNER\\nExecutive Profile\\n\\nObjective: Driven,...             53  \n",
            "1  ASSOCIATE DIRECTOR BUSINESS DEVELOPMENT\\nSumma...             48  \n",
            "2  SHORE SENIOR CONSTRUCTION PIPING ENGINEER\\nPro...             48  \n",
            "3  DIRECTOR OF THEATER\\nHighlights\\n\\nEdline, Goo...             47  \n",
            "4  INFORMATION TECHNOLOGY SPECIALIST (WEB), GS-11...             47  \n",
            "5  FINANCE AND OPERATIONS MANAGER\\nExecutive Prof...             47  \n",
            "6  IT CONSULTANT\\nProfessional Summary\\nSupport E...             46  \n",
            "7  ACCOUNTANT III\\nSummary\\n\\nEnergetic mother of...             46  \n",
            "8  DIGITAL MARKETING SPECIALIST\\nSummary\\nDigital...             46  \n",
            "9  DIVISION OPERATIONS & RISK OVERSIGHT MANAGER\\n...             41  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "cv_data = pd.read_csv('/content/drive/MyDrive/RecruitFlow/test_parsedCV.csv')\n",
        "cv_data = cv_data.dropna()\n",
        "\n",
        "job_data = pd.read_csv('/content/drive/MyDrive/RecruitFlow/job_descriptions.csv')\n",
        "job_data = job_data.dropna()\n",
        "\n",
        "# Split\n",
        "cv_train, cv_test = train_test_split(cv_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data and create TaggedDocuments for Doc2Vec\n",
        "train_corpus = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(cv_train['Parsed_text'])]\n",
        "test_corpus = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(cv_test['Parsed_text'])]\n",
        "\n",
        "# Train  Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(vector_size=300, window=5, min_count=1, workers=4, epochs=20)\n",
        "doc2vec_model.build_vocab(train_corpus)\n",
        "doc2vec_model.train(train_corpus, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
        "\n",
        "# Embed job descriptions and CVs into vectors\n",
        "job_vectors = [doc2vec_model.infer_vector(text.split()) for text in job_data['job_description']]\n",
        "cv_vectors = [doc2vec_model.infer_vector(text.split()) for text in cv_test['Parsed_text']]\n",
        "\n",
        "# Calculate cosine similarity between job descriptions and CVs\n",
        "similarity_matrix = cosine_similarity(job_vectors, cv_vectors)\n",
        "\n",
        "# Normalize the similarity scores to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "normalized_similarity = scaler.fit_transform(similarity_matrix.T).T\n",
        "\n",
        "# Reset the index of cv_test DataFrame\n",
        "cv_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "ranking_scores = normalized_similarity.argmax(axis=1) + 1\n",
        "\n",
        "# Add the 'Ranking_Score' column to cv_test\n",
        "cv_test['Ranking_Score'] = ranking_scores[:len(cv_test)]\n",
        "\n",
        "\n",
        "ranked_cvs_df = cv_test[['CV_ID', 'Parsed_text', 'Ranking_Score']].copy()\n",
        "\n",
        "# Display the first 10 ranked CVs\n",
        "top_10_cvs = ranked_cvs_df.sort_values(by='Ranking_Score', ascending=False).head(10).copy()\n",
        "top_10_cvs['CV_ID'] = top_10_cvs['CV_ID'].apply(lambda x: x.replace('/content/drive/MyDrive/RecruitFlow/ResumeDataset/', ''))\n",
        "\n",
        "top_10_cvs.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(top_10_cvs)\n",
        "\n"
      ]
    }
  ]
}